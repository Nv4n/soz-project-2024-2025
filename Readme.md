# Recommender System

> Реализирайте система за генериране на препоръка за закупуване на книги
> (recommender system). Може да използвате мярка за сходство между потребителите
> на книги въз основа на техните рейтингови записи или друго сходство, за да
> отправяте препоръки към читателите.

## Кратко описание на задачата

> Система за препоръки на книги, като препоръките се базират на рейтинг от читателите/потребителите чрез корелация по рейтинг и прилагането на k-NN алгоритъма. На данните би могло да се приложи ре-филтрация по жанрове и по възраст на читателите (евентуално). Основен проблем, който би следвало да се реши преди ре-филтрацията е, че 40% от читателите не са посочили възрастта си, което води до нужда от поправки/зачистване в данните преди ре-филтрацията.

## Данните

> Таблиците, които описваме по-долу са взети от [DATASET](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset). Ресурсът е цитиран и по-долу в графа ресурси.

### Users

> Таблица, която съдържа информация за потребителите, наричани още читатели в рамките на нашата система. Информацията, която се съхранява за читателите е техните уникални идентификационни номера (User-ID), локациите им (Location) и възрастта им. Потребителските идентификатори са анонимизирани и съпоставими с цели числа. Данните за местоположението на читателите и тяхната възраст се предоставят, ако има такива. В противен случай тези полета приемат NULL стойности. Това предполага, че ако те бъдат включвани в методите за категоризация и препоръки на книги на други потребители, трябва да се подсигурим за коректността на данните и евентуално да ги почистим от NULL стойности, тъй като те не внасят никаква информация и пречат на процеса по препоръка на книги.

### Books

> Таблица, която предоставя информация за книгите, от които имаме в наличност и ще можем да препоръчваме на нашите читатели. Книгите са уникално идентифицируеми от техните ISBN номера като трябва предварително да се погрижим, че всички ISBN номера са уникални и валидни. Таблицата също така предоставя информация за съдържанието на книгата като загавие на книгата (Book-Title), автор на книгата (Book-Author), година на публикация на книгата (Year-Of-Publication) и издателство на книгата (Publisher). **Тази информация е предоставена от Amazon Web Services.** Трябва да се отбележи също така, че при наличие на съавторство над някоя книга, само имената на първият автор са предоставени. В таблицата също така се съхранява информация за линка към корицата на съответната книга (линк към уеб сайта на Amazon). Тези линкове може да се показват под различни форми (Image-URL-S - къси, Image-URL-M - средно дълги, Image-URL-L - дълги).

### Ratings

> Таблица, която описва оценките на книгите. В нея се съдържа информация кой потребител (User-ID) коя книга (ISBN) а е оценил и каква е била самата оценка (число в интервала от 1 до 10, вписана в полето Book-Rating). Ако някоя книга все още не е била оценена от даден потребител, оценката, която автоматично се вписва в полето за оценка (Book-Rating) е 0.

## Описание на функционалността

> Препоръки за книги могат да се правят на базата на техния рейтинг, на базата на възрастовите групи сред потребителите на системата ни, които се очертават или на база двата компонента едновременно. Ако обаче препоръчваме книги на база двата компонента би следвало да се провери първо дали тези два компонента зависят един от друг по някакъв начин иначе една такава препоръка не би била състоятелна. Все пак ако се окаже, че има смисъл от нея трябва да имаме предвид подходите за реализацията на система с подобен тип препоръки.

**Следователно разглеждаме следните варианти за препоръки на базата на повече от 2 параметъра:**

### Препоръки на базата на повече от 2 параметъра чрез регресия и гранулирани изчисления:

> например: **рейтинг** - базов компонент на препоръката, **възрастово групиране на читателите** и **жанрово разпределение на книгите**;

- **Регресия**: [Regression article](https://www.sciencedirect.com/science/article/abs/pii/S0020025516301669)
- **Гранулирани изчисления**: [Granular computing article](https://www.sciencedirect.com/topics/computer-science/granular-computing)

> Очертават се основно 3 подхода:
> - **линейна регресия с параметри рейтинг, възрасти, жанрове** (като ги свеждаме до категорийни или числови променливи) или **друг вид регресия при по-сложни модели**;
> - **гранулиране на данните** (групираме жанровете в нови смесени жанрове и/или групираме възрастите в няколко възрастови групи, за да опростим модела и идентифицираме патърните и трендовете във всеки един от клъстърите);
> - **смесен подход** - клъстеризация на данните на база възраст и какви жанрове книги предпочитат за опростяване + регресия за всеки клъстер за по-прецизни изчисления за конкретната група хора, което да води до по-голяма персонализация на резултатите;

#### Идеи за реализация 
- k-NN алгоритъм
	1. Зареждаме необходимите библиотеки.
	2. Прочитаме данните в dataframe-ове и изследваме данните (големина, допълнителна информация за dataframe-овете, сортиране на данните, отпечатване на данните, зачистване от незначещи записи и 	т.н.).
 	3. Създаваме k-NN модела като използваме Евклидова метрика, Манхатанските разстояния като метрика или друга, подходяща за случая метрика. 
	4. Трениране на модела по някой от следните методи:
		- train/test - използва разделение на данните на тренировъчно и тестово множество, при което данните се разделят на тренировъчно и отделно тестово множество. Този подход позволява проста оценка на производителността на модела, но не използва пълноценно всички налични данни за обучение.
		- k-fold - използва k-кратна кръстосана валидация, при която множеството данни се разделя на k равни части. Моделът се обучава и оценява многократно, което осигурява по-цялостна оценка на производителността му и намалява влиянието на вариациите в данните. Въпреки това, този подход изисква много повече изчислителна мощ.
		- build full trainset - използва метода build_full_trainset(), което създава тренировъчно множество, включващо всички налични оценки от множеството данни. Тази опция е полезна, когато множеството данни е сравнително малко и е желателно максимално ефективно използване на информацията за обучение. Това позволява на модела да се учи от целия набор данни, което потенциално подобрява точността.
  	5. Предсказваме най-популярните книги и препоръчваме на читателите някои от тях.
  
[KNN_Regression_approach](https://medium.com/@leam.a.murphy/personalized-book-recommendations-with-k-nearest-neighbors-442ce4dad44c)
[GeekforGeeks-Recommender Systems using KNN](https://www.geeksforgeeks.org/recommender-systems-using-knn/)

> **Бележки**: k-NN алгоритъма е класификационен алгоритъм, който се базира на изчисления на разстоянията между текущо изследвания тестови пример и неговите k на брой най-близки съседи, така че да се открият най-добрите примери от някаква извадка данни и според тази класификация, те да бъдат препоръчани на потребителя на системата (в случая говорим за книги, които трябва да се препоръчат на определена група читатели със сходства помежду си). За тази цел ни трябва определена метрика, която често пъти е Евклидово или Мнахатанско разстояние между дадените тестови примери и техните най-близки съседи (за простота).
> - Евклидово разстояние: Ако точката A(x1, y1) и точката B(x2, y2) , то dAB = sqrt((x1 - x2)^2 + (y1 - y2)^2) - [Euclidean distance](https://www.geeksforgeeks.org/euclidean-distance)
> - Манхатанско разстояние: Ако точката A(x1, y1) и точката B(x2, y2) , то dAB = |x1 - x2| + |y1 - y2| - [Manhattan distance](https://www.datacamp.com/tutorial/manhattan-distance)
>
> Тези метрики обаче не са достатъчно добри за нашата задача, защото те допускат дори и вземането на всички примери (в случая книги), които са на горе-долу еднакво разстояние от текущо тествания, а **cousine метриката** - взема предвид и ъгъла, под който се намира съседа на текущо тествания пример спрямо текущо тествания пример и въз основа на това колко фолям е ъгълът решава кой съсед (в случая книга) да добави в препоръчаните.

### Реализацията по същество

## Експерименти

### Резултати от проведените експерименти

## Още ресурси
[DATASET](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset)

За информация по [темата](https://towardsdatascience.com/how-did-we-build-bookrecommender-systems-in-an-hour-the-fundamentals-dfee054f978e)
и [темата](https://towardsdatascience.com/how-did-we-build-book-recommender-systems-in-anhour-%20part-2-k-nearest-neighbors-and-matrix-c04b3c2ef55c)

### Starter Kernel(s)

[Recom I: Data Understanding and Simple Recommendation](https://www.kaggle.com/arashnic/recom-i-data-understanding-and-simple-recomm)

### Повече информация

#### My Recommendation Article Series in Medium:

[Evolution of Recommendation Algorithms, Part I: Fundamentals , History Overview, Core and Classical Algorithms](https://medium.com/@anicomanesh/evolution-of-recommendation-algorithms-part-i-fundamentals-and-classical-recommendation-bb1c0bce78a9)
